{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c7b09f6-e20d-4753-9228-efed4b420dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f91a9237c70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from argparse import Namespace\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1288d56d-2dad-4023-a3fd-1ba3ecd05ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a629d2c-43bf-4b0e-a1dd-169bba145794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = 'data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c64aab6-9378-478e-afd5-0d8b85489054",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15ef4dc-6353-4063-a71f-cc351e503892",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d69513-55f1-4565-a8bc-804b81a91d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, n_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035963e2-3431-451b-b0a1-3e035cdc7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5491d590-6f5b-476b-8dd2-152fc3384ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d8c9744-c3f6-4c74-afc8-d10648d059aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fbca6d2-119e-487b-9955-6ea1efac3752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                 [1.0, 2.0, 3.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3cddc81-ad17-4b33-b7ce-c387c4a36cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f53e675-6063-4be9-be71-a7924d876b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run the model before training it\n",
    "img, _ = cifar2[0]\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10794c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "172349c2-7825-42e0-9c46-be871a80ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4784, 0.5216]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d3d0f3-e741-4885-ab14-8a0451e30e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ec853e-cd16-4069-9683-375a1e2ea13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5077, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.LogSoftmax(dim=1))\n",
    "\n",
    "loss = nn.NLLLoss()\n",
    "\n",
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6552606-9a1d-44ad-9609-92d7ef3ec3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, model, loss_fn, optimizer, data):\n",
    "    for epoch in range(n_epochs):\n",
    "        for img, label in cifar2:\n",
    "            out = model(img.view(-1).unsqueeze(0))\n",
    "            loss = loss_fn(out, torch.tensor([label]))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print('Epoch: %d, Loss %f' % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c155c40-d4ba-45a0-afc7-761ef7e8ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss 4.550541\n",
      "Epoch: 1, Loss 8.139921\n",
      "Epoch: 2, Loss 1.761541\n",
      "Epoch: 3, Loss 5.512603\n",
      "Epoch: 4, Loss 8.465409\n",
      "Epoch: 5, Loss 9.054122\n",
      "Epoch: 6, Loss 11.672654\n",
      "Epoch: 7, Loss 9.560898\n",
      "Epoch: 8, Loss 10.466570\n",
      "Epoch: 9, Loss 15.005644\n",
      "Epoch: 10, Loss 2.994224\n",
      "Epoch: 11, Loss 5.336022\n",
      "Epoch: 12, Loss 10.343336\n",
      "Epoch: 13, Loss 11.061426\n",
      "Epoch: 14, Loss 13.589913\n",
      "Epoch: 15, Loss 10.360228\n",
      "Epoch: 16, Loss 6.262290\n",
      "Epoch: 17, Loss 20.382130\n",
      "Epoch: 18, Loss 0.016537\n",
      "Epoch: 19, Loss 16.350868\n",
      "Epoch: 20, Loss 13.284583\n",
      "Epoch: 21, Loss 6.852813\n",
      "Epoch: 22, Loss 9.969567\n",
      "Epoch: 23, Loss 1.023360\n",
      "Epoch: 24, Loss 6.608681\n",
      "Epoch: 25, Loss 6.144263\n",
      "Epoch: 26, Loss 13.384688\n",
      "Epoch: 27, Loss 8.928279\n",
      "Epoch: 28, Loss 14.362111\n",
      "Epoch: 29, Loss 6.275534\n",
      "Epoch: 30, Loss 5.441781\n",
      "Epoch: 31, Loss 13.068040\n",
      "Epoch: 32, Loss 17.097883\n",
      "Epoch: 33, Loss 4.326817\n",
      "Epoch: 34, Loss 13.274837\n",
      "Epoch: 35, Loss 11.035848\n",
      "Epoch: 36, Loss 12.313710\n",
      "Epoch: 37, Loss 16.075966\n",
      "Epoch: 38, Loss 11.091454\n",
      "Epoch: 39, Loss 5.735734\n",
      "Epoch: 40, Loss 8.619163\n",
      "Epoch: 41, Loss 1.488719\n",
      "Epoch: 42, Loss 4.943095\n",
      "Epoch: 43, Loss 10.252857\n",
      "Epoch: 44, Loss 13.116220\n",
      "Epoch: 45, Loss 19.036303\n",
      "Epoch: 46, Loss 13.799706\n",
      "Epoch: 47, Loss 8.210265\n",
      "Epoch: 48, Loss 12.946081\n",
      "Epoch: 49, Loss 13.915406\n",
      "Epoch: 50, Loss 21.087593\n",
      "Epoch: 51, Loss 14.927952\n",
      "Epoch: 52, Loss 8.613293\n",
      "Epoch: 53, Loss 13.245205\n",
      "Epoch: 54, Loss 6.345863\n",
      "Epoch: 55, Loss 7.862024\n",
      "Epoch: 56, Loss 17.085957\n",
      "Epoch: 57, Loss 7.199379\n",
      "Epoch: 58, Loss 13.993472\n",
      "Epoch: 59, Loss 15.391697\n",
      "Epoch: 60, Loss 17.539520\n",
      "Epoch: 61, Loss 17.236908\n",
      "Epoch: 62, Loss 14.811680\n",
      "Epoch: 63, Loss 18.271835\n",
      "Epoch: 64, Loss 15.666254\n",
      "Epoch: 65, Loss 6.651162\n",
      "Epoch: 66, Loss 11.183827\n",
      "Epoch: 67, Loss 1.791535\n",
      "Epoch: 68, Loss 8.470437\n",
      "Epoch: 69, Loss 5.773393\n",
      "Epoch: 70, Loss 8.748476\n",
      "Epoch: 71, Loss 14.085135\n",
      "Epoch: 72, Loss 14.343318\n",
      "Epoch: 73, Loss 15.744448\n",
      "Epoch: 74, Loss 14.096459\n",
      "Epoch: 75, Loss 7.582710\n",
      "Epoch: 76, Loss 17.231247\n",
      "Epoch: 77, Loss 12.640161\n",
      "Epoch: 78, Loss 10.865116\n",
      "Epoch: 79, Loss 6.004977\n",
      "Epoch: 80, Loss 13.371978\n",
      "Epoch: 81, Loss 11.256004\n",
      "Epoch: 82, Loss 0.062497\n",
      "Epoch: 83, Loss 0.007096\n",
      "Epoch: 84, Loss 2.852103\n",
      "Epoch: 85, Loss 10.192029\n",
      "Epoch: 86, Loss 19.638687\n",
      "Epoch: 87, Loss 14.065538\n",
      "Epoch: 88, Loss 18.152994\n",
      "Epoch: 89, Loss 11.746683\n",
      "Epoch: 90, Loss 3.751439\n",
      "Epoch: 91, Loss 14.106717\n",
      "Epoch: 92, Loss 2.827079\n",
      "Epoch: 93, Loss 4.921416\n",
      "Epoch: 94, Loss 12.606582\n",
      "Epoch: 95, Loss 5.990628\n",
      "Epoch: 96, Loss 10.352303\n",
      "Epoch: 97, Loss 1.753077\n",
      "Epoch: 98, Loss 1.795395\n",
      "Epoch: 99, Loss 1.330555\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs=100\n",
    "\n",
    "training_loop(n_epochs=100,\n",
    "             model=model,\n",
    "             loss_fn=loss_fn,\n",
    "             optimizer=optimizer,\n",
    "             data=cifar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce79ae8e-854f-4417-885e-4c471f81e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss 0.594021\n",
      "Epoch: 1, Loss 0.492725\n",
      "Epoch: 2, Loss 0.436317\n",
      "Epoch: 3, Loss 0.509323\n",
      "Epoch: 4, Loss 0.431085\n",
      "Epoch: 5, Loss 0.572777\n",
      "Epoch: 6, Loss 0.240891\n",
      "Epoch: 7, Loss 0.322026\n",
      "Epoch: 8, Loss 0.436223\n",
      "Epoch: 9, Loss 0.490084\n",
      "Epoch: 10, Loss 0.348328\n",
      "Epoch: 11, Loss 0.278587\n",
      "Epoch: 12, Loss 0.275147\n",
      "Epoch: 13, Loss 0.503164\n",
      "Epoch: 14, Loss 0.246578\n",
      "Epoch: 15, Loss 0.256272\n",
      "Epoch: 16, Loss 0.292738\n",
      "Epoch: 17, Loss 0.182304\n",
      "Epoch: 18, Loss 0.333581\n",
      "Epoch: 19, Loss 0.330168\n",
      "Epoch: 20, Loss 0.568310\n",
      "Epoch: 21, Loss 0.314019\n",
      "Epoch: 22, Loss 0.224247\n",
      "Epoch: 23, Loss 0.199910\n",
      "Epoch: 24, Loss 0.228315\n",
      "Epoch: 25, Loss 0.181491\n",
      "Epoch: 26, Loss 0.283596\n",
      "Epoch: 27, Loss 0.213896\n",
      "Epoch: 28, Loss 0.192093\n",
      "Epoch: 29, Loss 0.225873\n",
      "Epoch: 30, Loss 0.290780\n",
      "Epoch: 31, Loss 0.202629\n",
      "Epoch: 32, Loss 0.086101\n",
      "Epoch: 33, Loss 0.103419\n",
      "Epoch: 34, Loss 0.156912\n",
      "Epoch: 35, Loss 0.246207\n",
      "Epoch: 36, Loss 0.142003\n",
      "Epoch: 37, Loss 0.291896\n",
      "Epoch: 38, Loss 0.257285\n",
      "Epoch: 39, Loss 0.129855\n",
      "Epoch: 40, Loss 0.107934\n",
      "Epoch: 41, Loss 0.059967\n",
      "Epoch: 42, Loss 0.124705\n",
      "Epoch: 43, Loss 0.053217\n",
      "Epoch: 44, Loss 0.222241\n",
      "Epoch: 45, Loss 0.059851\n",
      "Epoch: 46, Loss 0.103348\n",
      "Epoch: 47, Loss 0.043291\n",
      "Epoch: 48, Loss 0.040340\n",
      "Epoch: 49, Loss 0.127027\n",
      "Epoch: 50, Loss 0.050839\n",
      "Epoch: 51, Loss 0.062617\n",
      "Epoch: 52, Loss 0.103196\n",
      "Epoch: 53, Loss 0.112860\n",
      "Epoch: 54, Loss 0.065076\n",
      "Epoch: 55, Loss 0.049985\n",
      "Epoch: 56, Loss 0.015895\n",
      "Epoch: 57, Loss 0.023393\n",
      "Epoch: 58, Loss 0.043918\n",
      "Epoch: 59, Loss 0.027148\n",
      "Epoch: 60, Loss 0.092732\n",
      "Epoch: 61, Loss 0.158788\n",
      "Epoch: 62, Loss 0.201936\n",
      "Epoch: 63, Loss 0.102320\n",
      "Epoch: 64, Loss 0.021244\n",
      "Epoch: 65, Loss 0.048412\n",
      "Epoch: 66, Loss 0.036306\n",
      "Epoch: 67, Loss 0.042822\n",
      "Epoch: 68, Loss 0.033253\n",
      "Epoch: 69, Loss 0.031013\n",
      "Epoch: 70, Loss 0.016857\n",
      "Epoch: 71, Loss 0.019895\n",
      "Epoch: 72, Loss 0.044100\n",
      "Epoch: 73, Loss 0.061208\n",
      "Epoch: 74, Loss 0.015420\n",
      "Epoch: 75, Loss 0.055982\n",
      "Epoch: 76, Loss 0.024220\n",
      "Epoch: 77, Loss 0.030370\n",
      "Epoch: 78, Loss 0.031106\n",
      "Epoch: 79, Loss 0.010202\n",
      "Epoch: 80, Loss 0.011970\n",
      "Epoch: 81, Loss 0.036985\n",
      "Epoch: 82, Loss 0.041660\n",
      "Epoch: 83, Loss 0.050977\n",
      "Epoch: 84, Loss 0.015692\n",
      "Epoch: 85, Loss 0.003423\n",
      "Epoch: 86, Loss 0.007541\n",
      "Epoch: 87, Loss 0.021779\n",
      "Epoch: 88, Loss 0.010950\n",
      "Epoch: 89, Loss 0.005628\n",
      "Epoch: 90, Loss 0.008739\n",
      "Epoch: 91, Loss 0.015526\n",
      "Epoch: 92, Loss 0.020222\n",
      "Epoch: 93, Loss 0.016159\n",
      "Epoch: 94, Loss 0.011914\n",
      "Epoch: 95, Loss 0.006271\n",
      "Epoch: 96, Loss 0.009766\n",
      "Epoch: 97, Loss 0.011615\n",
      "Epoch: 98, Loss 0.016622\n",
      "Epoch: 99, Loss 0.018795\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "params = Namespace(DataLoader=torch.utils.data.DataLoader,\n",
    "                   dataset=cifar2,\n",
    "                  batch_size=64,\n",
    "                  shuffle=True,\n",
    "                  learning_rate=1e-2,\n",
    "                  optimizer=optim.SGD,\n",
    "                  loss_fn=nn.NLLLoss(),\n",
    "                  n_epochs=100)\n",
    "\n",
    "train_loader = params.DataLoader(params.dataset, batch_size=params.batch_size,\n",
    "                                shuffle=params.shuffle)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 2),\n",
    "    nn.LogSoftmax(dim=1))\n",
    "\n",
    "optimizer=params.optimizer(model.parameters(), lr=params.learning_rate)\n",
    "\n",
    "for epoch in range(params.n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch: %d, Loss %f' % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0931f8c4-a777-47e3-8347-9674f82b9ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %f 0.8175\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                        shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print('Accuracy: %f', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad152d5a-2b70-4ea4-bc60-6016bbeae018",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_model = nn.Sequential(\n",
    "    nn.Linear(3072, 1024),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(128, 2),\n",
    "    nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b035a875-2c45-4612-bc96-f8f72dcd9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = nn.Sequential(\n",
    "    nn.Linear(3072, 1024),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(128, 2))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "036159ec-73d6-476b-9258-08124c38a0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737474, [3145728, 1024, 524288, 512, 65536, 128, 256, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel() for p in connected_model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12e0548e-dc15-4df3-8e5f-b59ef5e82d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel_list = [p.numel() for p in first_model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad3bef50-b1c9-49e1-b081-66aa69b0cde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3145728, 1024, 524288, 512, 65536, 128, 256, 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60b60659-9165-43d5-b0ba-9b3644dca21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e104c-3163-4b69-a615-deeb69e1c21f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

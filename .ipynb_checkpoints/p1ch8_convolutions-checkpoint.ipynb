{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec958e89-f329-4a4e-8b9c-459150bee29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff009358cb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from argparse import Namespace\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6521756-1221-4d1a-a52c-6a3c4701e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8035529-474a-4e10-bd4c-633e13ca226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = 'data-unversioned/p1ch6/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432425af-0574-4ed7-943b-6caee6768d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db380a-b28f-4467-82cd-9a60c65ccb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4c9b6-2848-4fa2-8c55-2245c0fba24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3343270-b0cf-4f7a-9ddc-81141b4ba9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel_list = [p.numel()\n",
    "              for p in connected_model.parameters()\n",
    "              if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6fd6c0-97e9-4ecc-a1bb-1df1aedd5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = nn.Sequential(\n",
    "                nn.Linear(3072, 512),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(512, 2),\n",
    "                nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058f2e2-844d-43d1-925e-4b875775a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel_list = [p.numel() for p in first_model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6f91e-0d15-44de-9dc3-b9701417daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31caadbe-7ab6-4853-98f8-a7033dad1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc3ed6e-b942-410c-a1ae-87124301b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight.shape, conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a4f66-b93f-4527-a514-b3f2bd5660bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae895c3-b84c-4ec5-8b2b-d0ee8abea98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef6e09-0260-480d-956a-c9982b50df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(nn.Conv2d)\n",
    "params = Namespace(\n",
    "    in_values=3,\n",
    "    out_values=1,\n",
    "    kernel_size=3,\n",
    "    padding=1)\n",
    "\n",
    "conv = nn.Conv2d(params.in_values, params.out_values, kernel_size=params.kernel_size,\n",
    "                padding=params.padding)\n",
    "output=conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8449e3-42f1-45a5-ab0f-9bfd7f756e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9813f5-dd2e-4830-84c5-16f599c46203",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20684d6-1b05-421d-b71c-3b4b9fe46dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Namespace(in_values=3,\n",
    "                  out_values=1,\n",
    "                  kernel_size=3,\n",
    "                  padding=1)\n",
    "\n",
    "conv = nn.Conv2d(params.in_values, params.out_values, kernel_size=params.kernel_size,\n",
    "                 padding=params.padding)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1, 0, 1],\n",
    "                                  [-1, 0, 1],\n",
    "                                  [-1, 0, 1]])\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7bbf0-94f0-4084-a082-463a5772788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59d218-227f-4c4a-bbba-fdd84e1cf21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "    nn.MaxPool2d(2),\n",
    "    #...\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d384d1-3dd2-4eb0-badf-f09c2942db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "    nn.MaxPool2d(2),\n",
    "    #...\n",
    "    nn.Linear(8 * 8 * 8, 32),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238d840-532e-4a9e-8bb8-19d673a73971",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43153ea-adbf-44a4-9c45-0accdd543fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model(img.unsqueeze(0))\n",
    "except RuntimeError as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea89b8-ca05-4671-bccb-1aae42e7b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(), #added to keep using nn.Sequential in models\n",
    "    nn.Linear(8 * 8 * 8, 32),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e40b9-1baa-4e46-bad6-d0285ce61086",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model(img.unsqueeze(0))\n",
    "except RuntimeError as e:\n",
    "    display(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a79bc9-1545-4c7f-935c-74b7b1b2cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7491ea5-b8d4-4af6-93fc-083d688ec406",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32327c79-1e62-49f4-85e7-f9b22567e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2a526-de79-45b4-9a91-be8d3950cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fd696-1e4b-44c3-b996-6341ea52111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13754910-67d1-4238-8129-28dfb80108f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb7377-1932-4c04-96e5-108b5a24fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4cb339-aa08-487b-a565-8eb3298473b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            \n",
    "            outputs = model(imgs)  # <4>\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "\n",
    "            optimizer.zero_grad()  # <6>\n",
    "            \n",
    "            loss.backward()  # <7>\n",
    "            \n",
    "            optimizer.step()  # <8>\n",
    "\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  # <10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f974d-3a5a-4dab-abbd-a2221f42fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "params = Namespace(n_epochs=100,\n",
    "                  optimizer=optim.SGD(model.parameters(), lr=1e-2),\n",
    "                  model=model,\n",
    "                  loss_fn=nn.CrossEntropyLoss(),\n",
    "                  train_loader=torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                                          shuffle=True))\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=params.n_epochs,\n",
    "    optimizer=params.optimizer,\n",
    "    model=params.model,\n",
    "    loss_fn=params.loss_fn,\n",
    "    train_loader=params.train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8320c-4fc8-4a03-8333-dcf32102afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = Namespace(\n",
    "    data=cifar2, batch_size=64,\n",
    "    shuffle=False)\n",
    "\n",
    "val_params = Namespace(\n",
    "    data=cifar2_val, batch_size=64,\n",
    "    shuffle=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_params.data, batch_size=train_params.batch_size,\n",
    "                                          shuffle=train_params.shuffle)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_params.data, batch_size=val_params.batch_size,\n",
    "                                        shuffle=val_params.shuffle)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    '''Takes a model and compares the results on the training and validation datasets.'''\n",
    "    for name, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int ((predicted == labels).sum())\n",
    "                \n",
    "            print(\"Accuracy {}: {:.2f}\".format(name, correct/total))\n",
    "            \n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e57660-4b32-4ac5-8b19-e6375dfc83ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afcd87e-632d-4dce-b6ce-30478d16c0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb2978-82c0-482b-aebf-33eccf317df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
